{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d70a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General \n",
    "import pandas as pd, numpy as np, requests, gc as gc, time as time, warnings\n",
    "from collections import Counter\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt, seaborn as sns, plotly, plotly.express as px\n",
    "\n",
    "# Other utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, classification_report, balanced_accuracy_score, f1_score\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "# Sampling\n",
    "from imblearn.over_sampling import ADASYN, SVMSMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Optimizers\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# Feature Importances\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# Other settings\n",
    "gc.enable()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bbbba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from Discord\n",
    "df = pd.read_csv('dataset.csv')\n",
    "labels = pd.DataFrame(requests.get('http://45.33.127.106:5000/site/labels/id00wund3rW1thML').json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a1f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data how we want it\n",
    "merged_df = pd.merge(df, labels, how=\"left\", left_on='label_id_x', right_on='id')\n",
    "bot_df = merged_df.loc[merged_df['label'].isin([x for x in merged_df['label'] if '_bot' in x])]\n",
    "final_df = bot_df.loc[:, ~bot_df.columns.isin([x for x in bot_df.columns if '_x' in x] + \\\n",
    "                                              ['Unnamed: 0', 'name', 'id', 'id_y', \n",
    "                                               'label_jagex_y', 'label_id_y', 'timestamp',\n",
    "                                               'created_at', 'updated_at', 'ts_date_y'])]\n",
    "classes = final_df['label']\n",
    "final_df.drop('label', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize some data\n",
    "\n",
    "# Set some preliminary settings\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "for col in final_df.columns:\n",
    "    sns.histplot(data=final_df, x=str(col), kde=True, \n",
    "                 stat='probability', bins=3).set(title='{} Probability Distribution'.format(str(col)))\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8abc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how the data visualizes naturally\n",
    "umapper = umap.UMAP()\n",
    "umap_df = pd.DataFrame(data=umapper.fit_transform(StandardScaler().fit_transform(final_df)),\n",
    "                       columns=['UMAP-1', 'UMAP-2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af04d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the data as represented by UMAP\n",
    "plt.figure(figsize=(25, 15))\n",
    "sns.scatterplot(data=umap_df, x='UMAP-1', y='UMAP-2', hue=classes, palette=\"dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65003cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the same thing with PCA\n",
    "\n",
    "# We can estimate the # of principal components needed\n",
    "estimate_pca = PCA(n_components='mle').fit_transform(final_df)\n",
    "\n",
    "# Let's also grab a 2D plot\n",
    "plot_pca = PCA(n_components=2).fit_transform(final_df)\n",
    "pca_df = pd.DataFrame(data=PCA(n_components=2).fit_transform(final_df),\n",
    "                       columns=['PCA-1', 'PCA-2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7305d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many components are needed to explain proper variance\n",
    "print(\"Optimal # of components: {}\".format(estimate_pca.shape[1]))\n",
    "print(\"All components: {}\".format(final_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8562909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data in 2D using PCA\n",
    "plt.figure(figsize=(25, 15))\n",
    "sns.scatterplot(data=pca_df, x='PCA-1', y='PCA-2', hue=classes, palette=\"dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd54b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to optimize KMeans algorithm\n",
    "def optimize_kmeans(data, labels):\n",
    "    k = []\n",
    "    sil = []\n",
    "    for cluster_count in range(2, len(set(labels))):\n",
    "        kmeans = KMeans(n_clusters=cluster_count, random_state=30)\n",
    "        # Append silhouette scores and cluster counts to some lists\n",
    "        sil.append(silhouette_score(final_df, kmeans.fit_predict(final_df)))\n",
    "        k.append(cluster_count)\n",
    "    \n",
    "    #return {k:v for k,v in zip(k, sil)}\n",
    "    return k, sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4049867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's optimize the kmeans algorithm for our case\n",
    "ks, sil_scores = optimize_kmeans(final_df, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the optimal # of clusters\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.lineplot(x=ks, y=sil_scores).set(title=\"KMeans Silhouette Coefficient Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a list of models to test\n",
    "classifiers = [LogisticRegression(), RidgeClassifier(), Perceptron(), GaussianNB(), MultinomialNB(),\n",
    "               BernoulliNB(), MLPClassifier(), RandomForestClassifier(), AdaBoostClassifier(), \n",
    "               ExtraTreesClassifier(), DecisionTreeClassifier(), ExtraTreeClassifier(), XGBClassifier(),\n",
    "               LGBMClassifier(), SVC()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e558f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's run all the classifiers without doing any sampling\n",
    "def run_classification(data, classes, classifiers):\n",
    "    # Metrics to report on\n",
    "    clfs = []\n",
    "    bal_acc = []\n",
    "    bal_f1 = []\n",
    "    times = []\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, classes, stratify=classes, random_state=30,\n",
    "                                                       test_size=0.2)\n",
    "    \n",
    "    # Now test each classifier\n",
    "    for clf in classifiers:\n",
    "        # Get the name of the classifier\n",
    "        name = clf.__class__.__name__\n",
    "        \n",
    "        # Record the start time for processing\n",
    "        start = time.time()\n",
    "        \n",
    "        # Train the model and get predictions\n",
    "        \n",
    "        # Set up specific pipelines for certain models\n",
    "        if name in ['MLPClassifier', 'Perceptron']:\n",
    "            # MinMax scale the data\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            \n",
    "            clf.fit(X_train, y_train)\n",
    "            preds = clf.predict(X_test)\n",
    "        \n",
    "        # Otherwise, if its a linear model, try t\n",
    "        elif name in ['LogisticRegression', 'RidgeClassifier']:\n",
    "            # Standardize the data\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.fit_transform(X_test)\n",
    "            \n",
    "            clf.fit(X_train, y_train)\n",
    "            preds = clf.predict(X_test)\n",
    "        \n",
    "        # Otherwise:\n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "            preds = clf.predict(X_test)\n",
    "        \n",
    "        # Compute some metrics\n",
    "        balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
    "        balanced_f1 = f1_score(y_test, preds, average='weighted')\n",
    "        train_time = round(time.time() - start, 3)\n",
    "        \n",
    "        # Create a pretty print string\n",
    "        print_str = \"\"\"\n",
    "        Report for: {} , in {} seconds.\n",
    "        \n",
    "        Balanced Accuracy: {}\n",
    "        Balanced F1 Score: {}\n",
    "        \n",
    "        {}\n",
    "        \n",
    "        \"\"\".format(name, train_time, balanced_accuracy,\n",
    "                   balanced_f1, classification_report(y_test, preds))\n",
    "        \n",
    "        # Update the end user\n",
    "        print(print_str)\n",
    "        \n",
    "        # Update metrics\n",
    "        clfs.append(name)\n",
    "        bal_acc.append(balanced_accuracy)\n",
    "        bal_f1.append(balanced_f1)\n",
    "        \n",
    "        # Free up some memory\n",
    "        del(name, train_time, balanced_accuracy, balanced_f1)\n",
    "        gc.collect()\n",
    "\n",
    "    # Return an analyzeable df\n",
    "    return pd.DataFrame({'Classifier': clfs, 'Accuracy': bal_acc, 'F1': bal_f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c0ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a second function for some imbalanced classification\n",
    "def run_imbalanced_classification(X_train, X_test, y_train, y_test, classifiers):\n",
    "    # Metrics to report on\n",
    "    clfs = []\n",
    "    bal_acc = []\n",
    "    bal_f1 = []\n",
    "    times = []\n",
    "    \n",
    "    # Now test each classifier\n",
    "    for clf in classifiers:\n",
    "        # Get the name of the classifier\n",
    "        name = clf.__class__.__name__\n",
    "        \n",
    "        # Record the start time for processing\n",
    "        start = time.time()\n",
    "        \n",
    "        # Train the model and get predictions\n",
    "        \n",
    "        # Set up specific pipelines for certain models\n",
    "        if name in ['MLPClassifier', 'Perceptron']:\n",
    "            # MinMax scale the data\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            \n",
    "            clf.fit(X_train, y_train)\n",
    "            preds = clf.predict(X_test)\n",
    "        \n",
    "        # Otherwise, if its a linear model, try t\n",
    "        elif name in ['LogisticRegression', 'RidgeClassifier']:\n",
    "            # Standardize the data\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.fit_transform(X_test)\n",
    "            \n",
    "            clf.fit(X_train, y_train)\n",
    "            preds = clf.predict(X_test)\n",
    "        \n",
    "        # Otherwise:\n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "            preds = clf.predict(X_test)\n",
    "        \n",
    "        # Compute some metrics\n",
    "        balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
    "        balanced_f1 = f1_score(y_test, preds, average='weighted')\n",
    "        train_time = round(time.time() - start, 3)\n",
    "        \n",
    "        # Create a pretty print string\n",
    "        print_str = \"\"\"\n",
    "        Report for: {} , in {} seconds.\n",
    "        \n",
    "        Balanced Accuracy: {}\n",
    "        Balanced F1 Score: {}\n",
    "        \n",
    "        {}\n",
    "        \n",
    "        \"\"\".format(name, train_time, balanced_accuracy,\n",
    "                   balanced_f1, classification_report(y_test, preds))\n",
    "        \n",
    "        # Update the end user\n",
    "        print(print_str)\n",
    "        \n",
    "        # Update metrics\n",
    "        clfs.append(name)\n",
    "        bal_acc.append(balanced_accuracy)\n",
    "        bal_f1.append(balanced_f1)\n",
    "        \n",
    "        # Free up some memory\n",
    "        del(name, train_time, balanced_accuracy, balanced_f1)\n",
    "        gc.collect()\n",
    "\n",
    "    # Return an analyzeable df\n",
    "    return pd.DataFrame({'Classifier': clfs, 'Accuracy': bal_acc, 'F1': bal_f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the class distribution\n",
    "Counter(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data and a validation set\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(final_df, classes, stratify=classes, \n",
    "                                          random_state=30, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run our tests\n",
    "classification_df = run_classification(X_tr, y_tr, classifiers)\n",
    "# View the results\n",
    "classification_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's run this again with the PCA representation\n",
    "classification_pca_df = run_classification(PCA(n_components=(estimate_pca.shape[1])).fit_transform(X_tr), \n",
    "y_tr, classifiers)\n",
    "# View the results\n",
    "classification_pca_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e667a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's try some sampling techniques to get us even better\n",
    "tomek_link_sampler = TomekLinks(sampling_strategy='majority')\n",
    "adasyn_sampler = ADASYN(sampling_strategy='not majority', random_state=30, n_neighbors=3)\n",
    "svm_sampler = SVMSMOTE(sampling_strategy='not majority', random_state=30, k_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2840c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, remove TomekLinks\n",
    "tl_data, tl_classes = tomek_link_sampler.fit_resample(X_tr, y_tr)\n",
    "\n",
    "# Then, create two oversampled representations of the data\n",
    "ada_data, ada_classes = adasyn_sampler.fit_resample(tl_data, tl_classes)\n",
    "svm_data, svm_classes = svm_sampler.fit_resample(tl_data, tl_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b039f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ADASYN Algorithm\n",
    "ada_df = run_imbalanced_classification(ada_data, X_te, ada_classes, y_te, classifiers)\n",
    "# View the results\n",
    "ada_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ab595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SVMSMOTE Algorithm\n",
    "svm_df = run_imbalanced_classification(svm_data, X_te, svm_classes, y_te, classifiers)\n",
    "# View the results\n",
    "svm_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's combine all of the different representations, and figure out who performed the \"best\"\n",
    "\n",
    "# Add data representation \n",
    "classification_df['data'] = 'normal'\n",
    "classification_pca_df['data'] = 'pca'\n",
    "ada_df['data'] = 'ADASYN'\n",
    "svm_df['data'] = 'SVMSMOTE'\n",
    "\n",
    "# Combine all into one dataframe\n",
    "combined_results_df = pd.concat([classification_df, classification_pca_df, ada_df, svm_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8606493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_results_df['Score'] = combined_results_df[['Accuracy', 'F1']].mean(axis=1)\n",
    "combined_results_df.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b101a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we know the \"best\" models to use, let's train them officially\n",
    "mlp = MLPClassifier().fit(MinMaxScaler().fit_transform(svm_data), svm_classes)\n",
    "lgb = LGBMClassifier().fit(svm_data, svm_classes)\n",
    "rfc = RandomForestClassifier().fit(svm_data, svm_classes)\n",
    "lrc = LogisticRegression().fit(StandardScaler().fit_transform(svm_data), svm_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453aa75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shap for LightGBM\n",
    "explainer = shap.TreeExplainer(lgb)\n",
    "shap_vals = explainer.shap_values(shap.sample(X_te, 100))\n",
    "shap.summary_plot(shap_vals, max_display=15, feature_names=X_tr.columns, class_names=lgb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shap for RandomForest\n",
    "explainer = shap.TreeExplainer(rfc, shap.sample(svm_data, 100))\n",
    "shap_vals = explainer.shap_values(shap.sample(X_te, 100))\n",
    "shap.summary_plot(shap_vals, max_display=15, feature_names=X_tr.columns, class_names=rfc.classes_)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ecfd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shap for LogisticRegression\n",
    "explainer = shap.LinearExplainer(lrc, shap.sample(svm_data, 100))\n",
    "shap_vals = explainer.shap_values(shap.sample(X_te, 100))\n",
    "shap.summary_plot(shap_vals, max_display=15, feature_names=X_tr.columns, class_names=lrc.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c112fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shap for MLP\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, shap.sample(svm_data, 50))\n",
    "shap_vals = explainer.shap_values(shap.sample(X_te, 50))\n",
    "shap.summary_plot(shap_vals, max_display=15, feature_names=X_tr.columns, class_names=mlp.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64938b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hotfix for an incompatability issue with scikit-optimize and scikit-learn\n",
    "# Documented https://github.com/scikit-optimize/scikit-optimize/pull/988\n",
    "class FixedBayesSearchCV(BayesSearchCV):\n",
    "    def __init__(self, estimator, search_spaces, optimizer_kwargs=None,\n",
    "                n_iter=50, scoring=None, fit_params=None, n_jobs=1,\n",
    "                n_points=1, refit=True, cv=None, verbose=0,\n",
    "                pre_dispatch='2*n_jobs', random_state=None,\n",
    "                error_score='raise', return_train_score=False):\n",
    "\n",
    "        # Bug fix: Added this line\n",
    "        self.fit_params = fit_params\n",
    "\n",
    "        self.search_spaces = search_spaces\n",
    "        self.n_iter = n_iter\n",
    "        self.n_points = n_points\n",
    "        self.random_state = random_state\n",
    "        self.optimizer_kwargs = optimizer_kwargs\n",
    "        self._check_search_space(self.search_spaces)\n",
    "\n",
    "        # Removed the passing of fit_params to the parent class.\n",
    "        super(BayesSearchCV, self).__init__(\n",
    "                estimator=estimator, scoring=scoring, n_jobs=n_jobs,\n",
    "                refit=refit, cv=cv, verbose=verbose, pre_dispatch=pre_dispatch,\n",
    "                error_score=error_score, return_train_score=return_train_score)\n",
    "\n",
    "    def _run_search(self, x):\n",
    "        raise BaseException('Use newer skopt')\n",
    "        \n",
    "# Let's optimize some hyperparameters\n",
    "\n",
    "# This should be done with a better search and across all models, but setting it up just for one right now\n",
    "param_grid = {\n",
    "    'penalty': Categorical(['l1', 'l2', 'elasticnet', 'none']),\n",
    "    'fit_intercept': Categorical([True, False]),\n",
    "    'C': Real(1, 10),\n",
    "    'tol': Real(1e-6, 1e+1),\n",
    "    'multi_class': Categorical(['auto', 'ovr', 'multinomial']),\n",
    "    #'solver': Categorical(['lbfgs', 'sag', 'saga'])\n",
    "}\n",
    "\n",
    "optimizer = FixedBayesSearchCV(estimator=LogisticRegression(), \n",
    "                          search_spaces=param_grid, \n",
    "                          n_jobs=2, cv=3, verbose=1)\n",
    "\n",
    "# Optimize the model\n",
    "optimizer.fit(svm_data, svm_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33c5a21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
